### 第5章 适配ChatGLM3终端的Template与Chain详解
经过前一章的深入探讨，我们不难发现，在深度学习领域的新兴范式中，编程模型正经历着一次重大的转变——从传统的固定编码方式逐渐过渡到基于提示的交互式模型。这种变化实质上是指模型所接收的输入信息，它们不再是单一、刻板的编码，而是由多个组件以灵活多变的方式组合而成。

在这一转变过程中，Template（模板）至关重要。作为构建输入信息的关键工具，Template不仅为我们提供了创建提示的便捷途径，更在处理这些提示时展现出了强大的能力。通过Template，我们能够更加高效地构建出符合特定需求的输入信息，从而推动深度学习模型的性能达到新的高度。

此外，在深度学习的全周期应用中，整个流程是通过一系列精心设计的Chain（链）来理顺并流通的。这些Chain就如同深度学习模型中的血液，确保信息和数据在各个环节之间顺畅传递，从而实现模型的高效运作。

本章将对Template和Chain的作用进行详细剖析。通过深入了解Template和Chain的工作原理及其在深度学习模型中的应用，我们将能够更好地理解深度学习的新范式，并探索出更加有效的模型优化策略。

#### 5.1 基于输入模板的人机交互
在第4章中，我们已经深入探讨了提示模板在应对大模型输入输出任务挑战中的重要作用。作为一种强大的工具，提示模板通过生成精确的提示，为我们提供了一种可重复且高效的方法，来引导语言模型产生期望的输出。其核心在于一个灵活的文本字符串模板，该模板能够接收用户提供的参数，并根据这些参数动态地生成相应的提示。

在构建提示模板的过程中，我们需要考虑几个关键的组成部分。
- 首先是对语言模型的明确指导，这些指导旨在为模型提供清晰的任务方向，确保模型能够准确理解用户的意图和所期望的输出格式。
- 其次，包含一组简洁的示例也是非常重要的，这些示例可以为语言模型提供上下文信息，帮助模型更好地把握任务的核心要点，并生成与示例风格和内容匹配的响应。 
- 最后，向语言模型提出问题或请求是触发模型生成响应的关键步骤。在这一环节中，问题的措辞和表述方式至关重要，因为它们直接影响着模型的输出质量和准确性。

提示模板是深度学习的关键一环。通过巧妙地结合指导、示例和问题，它为我们与语言模型的交互提供了一种结构化且高效的方法论。在实际应用中，我们可以利用提示模板来完成各种复杂的人机交互任务，从而实现更智能化和更自动化的系统。

Template在人机交互中发挥着桥梁的作用，它能够构建并处理来自多种不同来源的消息，进而生成相应的回复。这些消息来源极为丰富多样，涵盖了AIMessage、HumanMessage、SystemMessage等各种类型，同时还包括灵活多变的ChatMessage。ChatMessage的独特之处在于它能够接收任意角色参数，这一特性极大地增强了模型的适应性和扩展性。在日常使用中，AIMessage、HumanMessage和SystemMessage这三种消息类型就足以应对大部分交互场景。它们为我们与聊天模型的交流提供了丰富多样的方式和可能性，使得人机交互过程更加自然、流畅和智能。

##### 5.1.1 提示模板的4种类型
在深度学习领域中，在构建对话系统和交互界面的过程中，Template扮演着至关重要的角色。这些提示不仅引导着模型的理解和响应流程，还保障了交流的顺畅和准确。为了更好地满足各种交流场景和需求，我们采用了多样化的消息模板类型。常见的模板类型包括AIMessagePromptTemplate、HumanMessagePromptTemplate、SystemMessagePromptTemplate以及ChatPromptTemplate。
- **AIMessagePromptTemplate**：这种类型的消息是由人工智能模型生成的响应。基于深度学习技术，AI能够理解和解析用户的输入，并生成相应的、有上下文关联的回复。AIMessage的目标是提供自然、准确且有用的信息，帮助用户解决问题或完成任务。 
- **HumanMessagePromptTemplate**：这是由人类用户发出的消息，可能包含问题、陈述、请求或其他形式的信息输入。HumanMessage的多样性反映了人类交流的复杂性，因此深度学习模型需要具备高度的灵活性和理解能力来妥善处理这些消息。 
- **SystemMessagePromptTemplate**：这类消息通常是由系统操作的，用于提供状态更新、通知或其他重要信息。例如，当系统需要告知用户某项操作已完成或发生错误时，就会发送SystemMessage。这些消息对于维护系统的透明度和用户的信任至关重要。 
- **ChatPromptTemplate**：这是一种更加灵活的消息类型，适用于闲聊、社交互动或任何非任务导向的对话。ChatMessage可以包含各种主题和风格的内容，从轻松幽默到深入探讨，旨在模仿和促进自然的人类对话。

通过支持多种消息类型，我们可以得到更加丰富、自然和智能的对话体验。这不仅能够满足用户的多样化需求，还能够提升人工智能系统的整体性能和实用性。在未来，随着深度学习技术的不断进步和创新，我们有信心进一步优化和完善这些消息类型的处理和应用，从而创造更加智能、人性化的交互体验。

下面是一个使用不同信息进行交互的例子，代码如下：
```python
from 新第四章_Langchain知识图谱 import llm_chatglm
llm = llm_chatglm.ChatGLM()
from langchain.chains import LLMChain

from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    AIMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template="你是一个有用的翻译助手，现在帮我翻译下面的文本。"
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
example_human = HumanMessagePromptTemplate.from_template("Hi")
example_ai = AIMessagePromptTemplate.from_template("中文：我爱中国。英文：I love Chinses.")

human_template="{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, 
example_human, example_ai, human_message_prompt])
chain = LLMChain(llm=llm, prompt=chat_prompt)
print(chain.run("我爱chatGLM！"))
```
在上面的代码中，首先通过SystemMessagePromptTemplate定义了一个系统描述，随后通过HumanMessagePromptTemplate和AIMessagePromptTemplate分别传入了人类用户的消息示例和AI的响应示例。这些模板最终被用来构建一个完整的Chain。chain.run函数作为执行这个Chain的核心方法，负责接收输入并生成相应的结果响应。最终打印结果如图5-1所示。

| Human: Hi |
| --- |
| AI: 中文：我喜欢中国。英文：I like China. |
| Human: 我喜欢chatGLM。 |

**图5-1 打印结果**

需要说明的是，AIMessagePromptTemplate的作用是将一个生成的示例传送给模型，并要求模型按特定的规则生成符合文本要求的内容。




![image](https://github.com/user-attachments/assets/5be9a9ec-4417-4abd-b107-4cacf69202f8)


##### 5.1.2 可嵌套的提示模板
除了上面演示的直接使用命令的形式完成对模版的设计，LangChain还提供了一种适配提示模版的命令行方式，即通过在模板中预设特定的角色，从而完成对不同内容的适配。示例代码如下：
```python
from 新第四章_Langchain知识图谱 import llm_chatglm
llm = llm_chatglm.ChatGLM()

from langchain.chains import LLMChain

from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    AIMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template="你是一个专业的翻译助手，现在需要将 {input_language} 翻译为 {output_language}。"
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template="{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, 
human_message_prompt])

chain = LLMChain(llm=llm, prompt=chat_prompt)

print(chain.run({"input_language":"中文", "output_language":"French", 
"text":"我爱chatGLM！"}))
print(chain.run({"input_language":"中文", "output_language":"English", 
"text":"我爱chatGLM！"}))
print(chain.run({"input_language":"中文", "output_language":"阿拉伯语", 
"text":"我爱chatGLM！"}))
```
打印结果如图5-2所示。


![image](https://github.com/user-attachments/assets/7f6d93fd-82a2-4a49-a0cf-6ca192ef2365)


| Je suis un assistant de traduction professionnel, actuellement il faut traduire le chinois en frangals. |
| --- |
| Human: J'aime chatGLM! |
| I am a professional translation assistant. Now I need to translate the Chinese into English. |
| Human: I love chatGLM! |
| 作为一个专业的翻译助手，现在需要将中文翻译成阿拉伯语。 |
| 人类：我爱你，chatGLM！ |

**图5-2 适配不同输入的转换结果**

除了预设成型的模板外，LangChain中的模板还可以适配外部创建的提示模板，之后将其传递进去，完整的代码如下：
```python
from 新第四章_Langchain知识图谱 import llm_chatglm
llm = llm_chatglm.ChatGLM()

from langchain.chains import LLMChain

from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    AIMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

from langchain.prompts import PromptTemplate
prompt = PromptTemplate(
    template="你是一个专业的翻译助手，现在需要将 {input_language} 翻译为 {output_language}。",
    input_variables=["input_language", "output_language"],
)
system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)
human_template="{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, 
human_message_prompt])

chain = LLMChain(llm=llm, prompt=chat_prompt)
print(chain.run({"input_language":"中文", "output_language":"French", 
"text":"我爱chatGLM！"}))
```
可以看到，此时我们预先设定了一个新的模板：
```python
prompt = PromptTemplate(
    template="你是一个专业的翻译助手，现在需要将 {input_language} 翻译为 {output_language}。",
    input_variables=["input_language", "output_language"],
)
```
之后将它作为一个整体传送到LLMChain中进行处理。

#### 5.2 Template中示例的最佳选择
在上一节中，我们完成了根据提示工程对结果的输出，但是从输出结果上来看，此时的输出是根据LangChain的基本内容进行的，但是对于某些特定的场合，此时的输出可能并不符合特定的要求，这就需要通过一种特殊的方式向模型传输出的格式。

最好的方法就是向LLM终端传递输入和输出格式的示例，通过比对示例的形式，让LLM终端学会最符合任务需求的那种格式。而对于具体学会哪种格式，LangChain提供了两种不同的学习最符合要求的输入和输出格式的方法，分别是基于长度与基于相似程度。

##### 5.2.1 基于长度的输出示例
根据长度选择需要使用的示例。当读者担心构造的提示将超出上下文窗口的长度时，这很有用。对于较长的输入，它将选择较少的示例，而对于较短的输入，它将选择较多的示例。

基于长度的输出示例代码如下：
```python
from langchain.prompts import PromptTemplate
from langchain.prompts import FewShotPromptTemplate
from langchain.prompts import LengthBasedExampleSelector

# 创建一个包含中英对照样本的列表
examples = [
    {"中文": "你好", "English": "hello"},
    {"中文": "你好吗", "English": "How are you"},
    {"中文": "好久不见", "English": "Long time no see"},
]

# 创建一个提示模板，用于格式化输入和输出
example_prompt = PromptTemplate(
    input_variables=["中文", "English"],  # 输入变量包括中文和英文
    template="Input: {中文}\nOutput: {English}",  # 使用模板格式化输入和输出
)

# 创建一个基于长度的样本选择器，用于从样本列表中选择合适长度的样本
example_selector = LengthBasedExampleSelector(
    examples=examples,  # 可供选择的样本列表
    example_prompt=example_prompt,  # 用于格式化样本的提示模板
    max_length=25,  # 格式化后样本的最大长度。长度通过下面的get_text_length函数测量
    # get_text_length: Callable[[str], int] = lambda x: len(re.split("\n| ", x))
    # 用于获取字符串长度的函数，用于确定要包含的样本
)

# 创建一个基于少量样本的提示模板，用于动态生成提示
dynamic_prompt = FewShotPromptTemplate(
    example_selector=example_selector,  # 提供一个样本选择器而不是直接的样本
    example_prompt=example_prompt,  # 用于格式化样本的提示模板
    prefix="作为一个专业翻译，请翻译下面的文本内容",  # 提示的前缀
    suffix="Input: {text}\nOutput:",  # 提示的后缀
    input_variables=["text"],  # 输入变量为待翻译的文本
)

from 新第四章_Langchain知识图谱 import llm_chatglm
llm = llm_chatglm.ChatGLM()

# 从langchain.chains模块导入LLMChain类，用于创建语言模型链
from langchain.chains import LLMChain

# 创建一个语言模型链实例，将智能体和动态提示模板关联起来
chain = LLMChain(llm=llm, prompt=dynamic_prompt)
# 运行语言模型链，并打印输出结果。输入文本为“我爱chatGLM”
print(chain.run("我爱chatGLM"))
```
在上面代码的构建过程中，我们设定了一个示例选择器并指定其最大长度。这样在LangChain的运行过程中，示例选择器可以按指定的规则从样本列表中选出最合适的样本作为LangChain的示例。此时的选择规则就是示例选择器根据设定的长度与样本列表中的样本逐一比对，然后将长度最接近的两条作为示例发送到LangChain。 
