### 第6章 ChatGLM3多文本检索的增强生成实战
本章将利用ChatGLM3大语言模型，结合LangChain技术，进一步完善财务报表信息的抽取与预警工作，并实现专用的财务报表信息搜索引擎，即实现一个项目框架——检索增强生成（Retrieval Augmented Generation，RAG），如图6-1所示。

检索增强生成是一种强大的技术，它为大语言模型提供了从各种数据源中检索到的信息，并作为生成答案的重要依据。这种技术的引入，极大地增强了LLM的信息处理能力和生成答案的准确性。


![image](https://github.com/user-attachments/assets/e5cc4274-2f37-45c6-bee3-dfca41166ae6)


在RAG的框架下，LLM不再仅仅依赖于其内部的知识库和预训练的数据来生成答案，而是能够实时地从外部数据源中检索相关信息。这些数据源可以包括互联网上的网页、学术论文、新闻报道、社交媒体帖子等，也可以是企业内部的数据库、文档库或知识图谱等。

通过使用RAG架构，我们能够更准确地定位目标文本，从而提取出更有价值的财务信息。同时，我们还将构建预警系统，以便在关键财务指标出现异常时及时发出警报。在本章中，我们将深入探讨如何实现这一目标。首先，将介绍如何结合ChatGLM3和LangChain技术来改进财务报表信息抽取的准确性和效率。接着，将讨论如何构建有效的预警系统，以及如何选择合适的预警指标和阈值。最后，将通过实际案例演示这一方法的有效性，并总结本章的主要内容和关键收获。

通过本章的学习，读者将掌握运用ChatGLM3和LangChain技术来优化财务报表信息的抽取与预警工作的方法。这将有助于我们更准确地把握公司的财务状况，及时发现潜在的风险和机会，从而为投资决策提供有力支持。

另外，为了演示搜索引擎的强大之处，本章特定选择了较长的文本内容（35万字）进行处理，在学习本章示例时，读者可以缩短或替换目标内容从而节省学习资源。

#### 6.1 使用自然语言处理方法对目标进行查找
在海量数据中查找目标是一项具有挑战性的任务，尤其是当目标文件夹中存在大量可选目标时。传统的查找方法通常基于查询目标从目标标题中进行检索，这在目标较少时或许可行，但在面对大量目标时，这种方法就显得力不从心。

为了解决这个问题，我们可以借鉴人类在自然语言中对目标进行查找的一般步骤：根据所要查询的内容，在待查找目标标题中进行筛选，这可以通过简单的文本比对实现。然而，从实施结果来看，由于自然语言的结构和语法比较复杂，从海量文本中定位特定目标，本身就是一项困难的任务。因此，我们需要寻找更有效的解决方案。

在本节中，我们将采用经典的LLM终端和BM25结合的方法，尝试解决从海量目标中查找目标内容的难题。BM25是一种广泛应用于信息检索领域的算法，它基于词频和逆文档频率来计算文档与查询的相关性。同时LangChain，我们提供了一种灵活且强大的提示工程框架，可以帮助我们更好地构建和训练模型。

通过结合LangChain和BM25，我们将能够更准确地从海量数据中定位目标内容。具体来说，首先利用LangChain对目标标题进行初步筛选，找出与查询内容相关的候选目标。然后使用BM25构建深度学习模型，对候选目标进行进一步的分类和排序，从而找出最符合查询需求的目标。

在接下来的内容中，将从数据准备、模型构建、训练与优化等方面介绍如何使用LangChain和BM25完成海量目标中的内容查找，并分享一些实用的经验和技巧。无论是深度学习领域的研究者还是应用开发者，相信这些内容都将为你提供有益的参考和启示。

##### 6.1.1 数据集的准备
本节的目标是根据查询的内容完成目标的定位。笔者在本章的随书代码中准备了一份少量的上市公司年报数据，我们将使用这份数据进行相关内容的查找。

首先是数据的读取，我们直接使用生成好的txt数据库。获取全部内容的代码如下：
```python
def find_txt_files(directory):
    txt_files = []
    # 遍历指定文件夹
    for root, dirs, files in os.walk(directory):
        # 遍历文件夹中的文件
        for file in files:
            # 检查文件是否以.txt结尾
            if file.endswith('.txt'):
                # 如果是.txt文件，将文件路径添加到列表中
                txt_files.append(os.path.join(root, file))
    return txt_files
```
在上面代码中，我们通过对名称的读取，生成了一个包含全量文本名称的数据列表，内容如图6-2所示。

这里使用的是全量财务报表文本，对于普通读者来说，为了节省硬件，可以使用部分数据集进行验证。笔者经过测试，无论是总量数据还是部分数据，对代码执行结果都没有什么影响。


![image](https://github.com/user-attachments/assets/d69a707c-0a04-45af-aeff-56e6b371bf4a)


##### 6.1.2 分别基于BM25与LLM终端进行目标查找的方法
为了节省资源，在这里将采用部分数据集的目录作为查找内容。对于一个查找目标来说，如果在小规模的数据集上无法成功找到，那么迁移到大型数据库上获得对应的结果则更为困难。

在开始目标查找之前，首先设置一个最简单的查询任务，查询内容如下：
```
query = "2020年工商银行境内优先股工行优1的股息是多少？"
```
可以看到，在完成这个查询之前，需要从文本库中检索特定内容的文本。下面我们将依次使用BM25与LLMChain完成对目标文本的定位。

1. **基于BM25的文本定位**

首先是基于BM25的文本内容定位。在前面章节中对BM25的算法和构成已经做了详细解释，下面直接使用它来定位文本，代码如下：
```python
import util_tools
file_names = util_tools.find_txt_files("./alltxt")
query = "2021年工商银行境内优先股工行优1的股息率是多少？"
from rank_bm25 import BM25Okapi
bm25 = BM25Okapi(file_names)
# 使用BM25模型查找最相似的文本
scores = bm25.get_scores(query)
import numpy as np
most_similar_index = np.where(scores == max(scores))[0][0] # scores.index(max(scores))
most_similar_text = file_names[most_similar_index]
print(f"Query: {query}")
print(f"Most similar text: {most_similar_text}")
```
在上面代码中，首先建立了标题列表，之后使用BM25直接查找最相近的内容。结果如图6-3所示。
```
Query: 2020年工商银行境内优先股工行优1的股息率是多少？
Most similar text:./alltxt/2022-03-31_中国工商银行股份有限公司_601398_工商银行_2021年_年度报告.txt
```

这里可以很明显地看到，此时的查询结果虽然接近于我们需要查询的内容，但是从细节上来看，这里的具体年份出现了错误，这个结果是不可接受的。

2. **基于LLM终端的目标定位**

下面把目标定位（目标查找）放置在大模型上实现，这需要依靠我们之前学习过的内容，即通过设定Prompt的方法完成大模型的目标定位。


![image](https://github.com/user-attachments/assets/8b2635c3-326c-44fb-8812-a6b4a6ec6428)


首先需要完成的模板Prompt的构建，代码如下：
```python
from langchain.prompts import PromptTemplate
prompt = PromptTemplate(
    input_variables=["query", "file_names"],
    template="""作为一名财务检索专家，有如下的数据库{file_names}可供你查询。现在传递给你一个检索信息{query}，找到你认为的最具有相关性的那条文本内容。
输入：'帮我查一下2020年中公教育的营业收入是多少' 输出：'./alltxt/2020-03-10_中公教育科技股份有限公司_002607_中公教育_2020年_年度报告.txt'
输入：'找一下三峡水利2008年的上交税款' 输出：'./alltxt/2020-03-10_深圳市中金岭南有色金属股份有限公司_000060_中金岭南_2008年_年度报告.txt'
你要只输出内容，回复中不要带有输入的内容。
如果找不到对应的内容，则回答'未找到对应文本'
"""
)
```
下面完成基于大模型的文本查找，代码如下：
```python
from 新第四章_Langchain知识图谱 import llm_chatglm
# 这是一个用于生成剧情梗概的LLMChain
llm = llm_chatglm.ChatGLM()
from langchain.chains import LLMChain
chain = LLMChain(llm=llm, prompt=prompt)
new_query = (chain.run({"query":query, "file_names":file_names}))
print(new_query)
```
使用LLM终端进行文本比对之后，结果如下：
```
"未找到对应的文本"
```
可以看到，此时使用LLM终端查找对应的文本目标失败了，可能对于目前的模型性能来说，从大量的文本内容中比对和提取含有干扰项的文本是较为困难的。

注意：有时候作为LLM终端的大语言模型性能较强，可以直接找到对应的内容，但是，我们需要一个稳定的、可以供生产使用的、标准化的结果，这也是我们使用LLM终端和Prompt的理由。

最终从输出结果来看，无论是使用BM25还是单独使用LLM终端，都未能完成特定的目标查找任务。因此，我们需要寻找新的实现方式来完成目标定位。

##### 6.1.3 建立工业级标准化输出：LLM终端与BM25结合
上一节中，我们使用LLM终端与BM25分别进行目标查找，但是从结果上来看，并没有达到期望的目标。因此，我们需要找到一种更好的方法来实现这个需求。


经过分析可知，BM25和LLM终端不能较好地完成文本的比对，是因为查询内容的干扰较大。为了更精确地匹配结果，最简单的解决方案就是先将需要比对的内容提取出来，再将精炼提取后的文本作为匹配目标进行比对和查找。

1. **单独使用LLM终端完成新查询内容的提取**

如果希望实现对新查询内容文本的精确提取，可以设计一个专门的Prompt来实现这一目标。具体来说，可以将一些查询内容和其对应的提取结果作为示例，发送给大模型进行学习和模仿。通过这种方法，大模型将能够理解并学会在处理不同查询内容时，应该如何准确地提取出所需的信息。因此，在实际应用时，当我们输入新的查询内容时，大模型将能够依据先前学习的示例，精确地提取出我们所需要的内容。此时代码如下：
```python
query = "2021年工商银行境内优先股工行优1的股息是多少？"
from langchain.prompts import PromptTemplate
prompt = PromptTemplate(
    input_variables=["query"],
    template="""作为一名专业财务检索专家，现在传递给你一个检索信息{query}，你会一步一步地仔细思考，按步骤和要求完成任务。
1. 首先你要判定查询{query}有没有时间与公司名称，如果其中没有包含时间或者公司名称，则返回：查询内容不完全，更新查询内容。
2. 之后你只会从中抽取出时间与公司名称，不要额外内容，重新构成一句简短的语句输出。
你要严格按照下面的格式输出，不要有额外内容。
在满足要求后，按如下输出。
输入：'帮我查一下2020年长安汽车的营业收入是多少' 输出：'(时间:2020年,目标:长安汽车)'。
输入：'找一下三峡水利2008年的上交税款' 输出：'(时间:2008年,目标:三峡水利)'。
输入：'米哈游2010年的分红比率是多少' 输出：'(时间:2010年,目标:米哈游)'。
3. 最后你要验证输出结果，结果只有时间与公司名称，回复中不要带有输入的内容。
"""
)
from 新第四章_Langchain知识图谱 import llm_chatglm
llm = llm_chatglm.ChatGLM()
from langchain.chains import LLMChain
chain = LLMChain(llm=llm, prompt=prompt)
new_query = (chain.run({"query": query}))
print(new_query)
```
在上面代码中，我们采用同样的查询内容，希望借助LLMChain完成对目标的提取。在Prompt中，我们预先设定了部分模板，之后根据模板内容完成了对结果的抽取。最终输入和输出结果如图6-4所示。
```
输入：'查询2021年工商银行境内优先股工行优1的股息是多少' 输出：'(时间:2021年,目标:工商银行境内优先股工行优1)'。
```

可以很清楚地看到，此时查询文本得到修正，并获取了正确的结果。

2. **结合BM25的目标查找**


![image](https://github.com/user-attachments/assets/528e7898-7a74-4da4-8b60-869c6211582e)


下面示例根据新的查找内容，使用BM25来完成文本查找与比对，完整代码如下：

```python
query = "2021年工商银行境内优先股工行优1的票面股息率为是多少？"
from langchain.prompts import PromptTemplate
prompt = PromptTemplate(
    input_variables=["query"],
    template="""作为一名专业财务检索专家，现在传递给你一个检索信息{query}，你会一步一步地仔细思考，按步骤和要求完成任务。
1. 首先你要判定查询{query}有没有时间与公司名称，如果其中没有包含时间或者公司名称，则返回：查询内容不完全，更新查询内容。
2. 之后你只会从中抽取出时间与公司名称，不要额外内容，重新构成一句简短的语句输出。
你要严格按照下面的格式输出，不要有额外内容。
在满足要求后，按如下输出。
输入：'帮我查一下2020年长安汽车的营业收入是多少' 输出：'(时间:2020年,目标:长安汽车)'。
输入：'找一下三峡水利2008年的上交税款' 输出：'(时间:2008年,目标:三峡水利)'。
输入：'米哈游2010年的分红比率是多少' 输出：'(时间:2010年,目标:米哈游)'。
3. 最后你要验证输出结果，结果只有时间与公司名称，回复中不要带有输入的内容。
"""
)
from 新第四章_Langchain知识图谱 import llm_chatglm
# 这是一个用于生成的剧情梗概的LLMChain
llm = llm_chatglm.ChatGLM()
from langchain.chains import LLMChain
```
从代码中可以看到，此时将新修正后的查询内容输入模型中，结果如图6-5所示。
```
Query: 2021年工商银行境内优先股工行优1的股息是多少？
Most similar text:./alltxt/2022-03-31_中国工商银行股份有限公司_601398_工商银行_2021年_年度报告.txt
```
可以看到，此时结果较好地匹配我们需要查找的目标，而且查询内容和结果最接近。如果需要匹配其他查找内容，请读者自行尝试。


![image](https://github.com/user-attachments/assets/4242e6dc-f285-413e-809d-45a6e3a31b30)


#### 6.2 基于LLM终端完成文本内容抽取与文本问答
在上一节中，我们成功地获取了文本标题。本节将继续实现文本增强生成任务。我们将利用已获取的标题来找到对应的文本内容，并将这些文本与LLM终端相结合，以完成问题的抽取与回答工作。通过这种方式，我们能够进一步提高文本处理的效率和准确性。

##### 6.2.1 读取目标内容
首先，我们需要根据需求完成对目标内容的读取。这个比较简单，可以直接使用文本读取函数完成，代码如下：
```python
def get_single_jsonFile(file_path):
    import json
    context_list = []
    # 假设TXT文件的内容是这样的，每一行都是一个json对象
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
        for line in lines:
            # 将每一行的字符串转换为字典
            data = json.loads(line)
            # 提取并打印'inside'字段的值
            _line = (data.get('type') + " " + data.get('inside'))
            context_list.append(_line)
    return context_list
target_file = most_similar_text
context_list = get_single_jsonFile(target_file)
context = "".join(context_list)
print(context)
```
从上面代码中可以看到，target_file就是6.1.3节抽取得到的最相关的目标文本地址。结果如图6-6所示。

可以看到，此时读取了文本内容，并将它作为文本资料返回。


![image](https://github.com/user-attachments/assets/0fefb359-2580-4af9-9d7d-f1a0dd0c27e6)


##### 6.2.2 LangChain对文档的读取与分割方法

在将获取的文档分割并输入LLM终端之前，我们需要了解和掌握一些关键内容，即LangChain提供的函数。这些函数在后续的讲解过程中会遇到，掌握这些函数将有助于我们更有效地处理文档，并提升在LLM终端中的操作效率。

1. **文本的读取**


![image](https://github.com/user-attachments/assets/04631a72-8d5d-4ad9-97bb-fd472dafea1a)


文本的读取对于LangChain来说有多种形式，在这里主要讲解一下专用的TXT文本读取方法TextLoader，其他格式的读取方式与之类似。
```python
from langchain.document_loaders import TextLoader
loader = TextLoader("./tsinghua.txt", "utf-8")
pages = loader.load_and_split()
```
打印结果如图6-7所示。

可以看到，此时的文本被读取到内存中，而且作为pages被重新进行格式化和重载，具体结果就是被重载为一个字典格式以用于后续处理。 
