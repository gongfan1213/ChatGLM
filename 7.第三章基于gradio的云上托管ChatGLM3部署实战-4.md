### 文字内容
使用`MsDataset`类的`load`方法加载名为`cats_and_dogs`的训练数据集，指定了命名空间和分割方式为`train`
```python
ms_train_dataset = MsDataset.load(
    'cats_and_dogs', namespace='tany0699',
    subset_name='default', split='train')  # 加载训练集
```
# 注释掉的代码用于打印训练数据集的第一个元素，用于调试
# print(next(iter(ms_train_dataset)))

使用与上面相同的方式加载验证数据集，分割方式为`validation`
```python
ms_val_dataset = MsDataset.load(
    'cats_and_dogs', namespace='tany0699',
    subset_name='default', split='validation')  # 加载验证集
```
# 注释掉的代码用于打印验证数据集的第一个元素，用于调试
# print(next(iter(ms_val_dataset)))

导入`csv`模块，用于处理CSV文件，但在这段代码中未使用
```python
import csv
```
导入`os`模块，用于操作系统相关的功能
```python
import os
```
导入`transforms`模块，用于图像预处理
```python
from torchvision import transforms
```
导入`Image`类，用于图像的读取和操作
```python
from PIL import Image
```
导入`Dataset`类，用于自定义数据集
```python
from torch.utils.data import Dataset
```

定义一个自定义数据集类`DatasetLoader`，继承自`torch.utils.data.Dataset`
```python
class DatasetLoader(Dataset):
    # 初始化，接收一个参数data，通常是一个包含多个样本的列表或字典
    def __init__(self, data):
        self.data = data

    # 定义一个图像预处理方法，接收一个图像路径，返回预处理后的图像张量
    def preprocess_image(self, image_path):
        # 使用PIL库打开图像
        image = Image.open(full_path)
        # 定义一个图像变换序列，包括缩放、转为张量和标准化
        image_transform = transforms.Compose([
            transforms.Resize((256, 256)),  # 将图像缩放到256×256大小
            transforms.ToTensor(),  # 将PIL图像转换为PyTorch张量
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化图像
        ])
        # 应用图像变换并返回结果
        return image_transform(image)

    # 重写__getitem__方法，使其能够根据索引返回单个样本
    def __getitem__(self, index):
        # 从self.data中获取指定索引的图像路径和标签
        image_path, label = self.data[index]['image:FILE'], self.data[index]['category']
        # 调用preprocess_image方法对图像进行预处理
        image = self.preprocess_image(image_path)
        # 返回图像张量和整数标签
        return image, int(label)

    # 重写__len__方法，返回数据集的大小
    def __len__(self):
        return len(self.data)
```

使用自定义的`DatasetLoader`类包装从`MsDataset`加载的训练数据集
```python
data_train = DatasetLoader(ms_train_dataset)
```

在上面代码中，继承的`Dataset`是PyTorch中专用的数据读取类，一般由4个部分组成：
- `__init__`：接收1个输入参数`dataset`元组数据后，将读取后的数据存入`self.data`中，为后续读取图像做准备。
- `preprocess_image`：此函数用于图像预处理。首先，使用`PIL`（Python Imaging Library，现在通常称为`Pillow`）打开图像；接着，定义了一系列图像变换，即调整图像大小至256×256、转换图像为张量、对图像进行标准化处理；最后，返回预处理后的图像。
- `__getitem__`：当数据集类被循环调用时，`__getitem__`方法会返回指定索引的数据，即图像和标签。首先，它根据索引从`self.data`中取出图像路径和标签；然后，调用`preprocess_image`方法来处理图像数据；最后，将处理后的图像数据和标签转换为整型后返回。
- `__len__`：用于返回数据集的总图像数量。

![image](https://github.com/user-attachments/assets/21ef8501-e895-4c3a-8df1-b7a4128095e3)


### 3.2.2 模型的设计
运行环境和数据集准备好后，接下来需要完成模型的设计工作。我们可以采用PyTorch提供的模型包来完成这项工作，代码如下：
```python
import torchvision
from torchvision.models import ResNet50_Weights
# 加载预训练的ResNet50模型
model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
```

在下载完预训练模型后，结果如图3-18所示。

此外还需注意，对于提供的ResNet预训练模型，它是在1000类别的ImageNet上训练的结果，而目前我们仅需对2个类进行分类，因此还需要对它进行修改，把模型最后的全连接层的输出维度替换为2。完整代码如下：
```python
import torch
import torchvision
from torchvision.models import ResNet50_Weights
# 加载预训练的ResNet50模型
model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
num_classes = 2
# 将全连接层的输出维度替换为num_classes
in_features = model.fc.in_features
model.fc = torch.nn.Linear(in_features, num_classes)
device = "cuda"
model.to(device)
num_epochs = 20
lr = 1e-5
batch_size = 16
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
```

这是一个标准的代码实现方式，其中采用了交叉熵（`CrossEntropyLoss`）作为损失函数，而优化器（`optimizer`）选择`Adam`作为优化标准。

### 3.2.3 PyTorch模型训练的基本流程
前期安装的SwanLab库，需要在这一过程中使用`swanlab.init`设置实验名、实验介绍和记录超参数，代码如下：
```python
import swanlab
num_epochs = 20
lr = 1e-4
batch_size = 8
num_classes = 2
device = "cuda"
swanlab.init(
    # 设置实验名
    experiment_name="ResNet50",
    # 设置实验介绍
    description="Train ResNet50 for cat and dog classification.",
    # 记录超参数
    config={
        "model": "resnet50",
        "optim": "Adam",
        "lr": lr,
        "batch_size": batch_size,
        "num_epochs": num_epochs,
        "num_classes": num_classes,
        "device": device
    }
)
```
```python
# 数据载入部分
import get_data
from torch.utils.data import DataLoader

train_dataset = get_data.DatasetLoader(get_data.ms_train_dataset)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
```
```python
# model处理部分
import torch
import torchvision
from torchvision.models import ResNet50_Weights
# 加载预训练的ResNet50模型
model = torchvision.models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
# 将全连接层的输出维度替换为num_classes
in_features = model.fc.in_features
model.fc = torch.nn.Linear(in_features, num_classes)
model.to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
```
```python
# 模型训练部分
for iter, (inputs, labels) in enumerate(train_loader):
    inputs, labels = inputs.to(device), labels.to(device)
    optimizer.zero_grad()
    outputs = model(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()
    print('Epoch [{}/{}], Iteration [{}/{}], Loss: {:.4f}'.format(num_epochs, num_epochs, iter + 1, len(train_loader), loss.item()))
    swanlab.log({"train_loss": loss.item()})
```

上面代码只是简单地对模型进行总结计算，在一个循环周期中，调用`train_dataloader`，每次取出1个`batch_size`的图像和标签，传入ResNet50模型中得到预测结果，将结果和标签传入损失函数中计算交叉熵损失，最后根据损失计算反向传播，Adam优化器执行模型参数更新，如此循环往复。

### 3.2.4 可视化训练流程
在上一小节中，我们完成了训练流程的设计，下面通过格式化的方法对设计结果进行整合，代码如下：
```python
import swanlab

def train(model, device, train_dataloader, optimizer, criterion, epoch, num_epochs):
    model.to(device).train()
    for iter, (inputs, labels) in enumerate(train_dataloader):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(
            'Epoch [{}/{}], Iteration [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, iter + 1, len(train_dataloader),
                                                                    loss.item()))
        swanlab.log({"train_loss": loss.item()})


import torch

def test(model, device, test_dataloader, epoch):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in test_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = correct / total * 100
    print('Accuracy: {:.2f}%'.format(accuracy))
    swanlab.log({"test_acc": accuracy})
```

在上面代码中，我们分别定义了两个模块化函数`train`与`test`，它们的作用分别是对整体训练进行跟踪和测试。相对于在训练过程中对损失值的跟踪，在测试集中我们更倾向于对准确度的把握，因此在训练过程中，我们循环调用`test_dataloader`，将测试集的图像传入ResNet50模型中得到预测结果，再与标签进行比对，计算整体的准确率，并且利用`swanlab.log`跟踪它的变化。

对于可视化训练过程的具体使用，我们首先需要在终端CMD中定位到SwanLab存放log的文件夹。在弹出可视化地址后，打开页面进入监控模式，并且启动训练过程，从而开始模型的训练任务。

在SwanLab的监控页面中，我们可以很清楚地看到模型的可视化训练过程，即随着训练的进行，`loss`在降低，而准确率在上升，如图3-19所示。 

![image](https://github.com/user-attachments/assets/bafb0bba-ae6b-47be-84ff-b664e9e85381)
