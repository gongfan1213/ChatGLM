
![image](https://github.com/user-attachments/assets/32433fc6-0e5f-4dce-8f49-804fc58a593c)


生成的结果如图6 - 10所示。

["问：中国工商银行股份有限公司2021年的净稳定资金比例是多少？答：根据提供的文本材料，2021年净稳定资金比例为128.18%。",

"问：在2021年，中国工商银行股份有限公司有哪些其他资产？答：根据提供的文本材料，在2021年，中国工商银行股份有限公司的其他资产包括实物交易的大宗商品、提供的衍生产品初始保证金、净稳定资金比例衍生产品资产、相互依存的资产等。"]

图6 - 10 使用LLM终端完成的文本问答


可以看到，对于我们传送进LLM终端的文本，LLM可以很好地完成对答案的总结，并生成了若干条可供存储的问答材料。

# 6.3.2 存储提取后的内容
下面我们需要完成的是存储提取后的内容，此时选择使用JSON格式对数据进行存储，代码如下：

result = ["问：中国工商银行股份有限公司2021年的净稳定资金比例是多少？答：根据提供的文本材料，2021年净稳定资金比例为128.18%。",
"问：在2021年，中国工商银行股份有限公司有哪些其他资产？答：根据提供的文本材料，在2021年，中国工商银行股份有限公司的其他资产包括实物交易的大宗商品、提供的衍生产品初始保证金、净稳定资金比例衍生产品资产、相互依存的资产等。"]
target_file = "./alltxt/2022 - 03 - 31_中国工商银行股份有限公司_601398_工商银行_2021年_年度报告.txt"
split_id = 929 # 分片的段落序号


![image](https://github.com/user-attachments/assets/a94f34c1-cfc2-44ec-984d-851c2558887c)

```
import json
# 写入JSON文件，格式化为JSON数组，每个对象之间换行
with open('data.json', 'w', encoding='utf - 8') as f:
    # 写入一个以方括号开始的JSON数组
    f.write('[\n')
    for i, item in enumerate(result):
        # 使用json.dumps()来将字典转换为JSON字符串，并添加逗号和换行符
        f.write(json.dumps(item, ensure_ascii=False, indent=4))
        # 如果不是最后一个元素，添加逗号和换行符
        if i < len(result) - 1:
            f.write(',\n')
    # 写入结束方括号
    f.write('\n]')

print("数据已写入data.json文件，格式化为JSON数组，每个对象之间有换行分隔。")
````
在上面代码中，我们使用JSON格式存储数据，以便于后续的调用。我们不仅存储了问题与答案，还存储其来源以及分片的段落序号，这样的处理可以使我们妥善完成相关文本的查找。

### 6.4 本章小结
在本章中，我们深入探讨了利用ChatGLM3构建终端以高效处理多文档的方法。通过LLM终端与其他先进工具的完美融合，我们实现了更卓越的文本处理效果。
在探索过程中，我们引入了一种名为“检索增强生成”的智能问答模型。该模型的创新之处在于，它有效突破了大语言模型在知识领域上的局限性，为用户呈现了更加多样化和丰富的内容生成结果。这不仅增强了模型的实用性，也极大地拓宽了其应用场景。
此外，我们还开创性地设计了一种基于LLM终端的问题推演机制。这种机制能够引导我们更加聚焦于问题的核心，从而为解决更细致、更具体的问题提供了有力的手段。这一创新在提升问题解决的效率和准确性方面显示出巨大的潜力。
在完成上述研究的同时，本章也标志着利用LangChain辅助ChatGLM3学习的结束。接下来，将回归ChatGLM3本身，从源代码的角度进行深入分析，从而踏上一段全新的探索之旅。在这一过程中，我们希望揭示更多关于ChatGLM3工作原理的奥秘，并探索其在未来可能的优化与创新应用的方向。

第6章 ChatGLM3多文本检索的增强生成实战 | 131 
