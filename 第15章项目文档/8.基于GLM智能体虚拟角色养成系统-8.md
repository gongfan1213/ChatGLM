### 3. 部署ChatGLM3 - 6B
部署ChatGLM3 - 6B与部署微调的ChatGLM2 - 6B类似。首先进入源码中CharacterAI/langchain_glm3的路径下，执行“git lfs install”“git clone https://huggingface.co/THUDM/chatglm3 - 6b”和“git clone https://huggingface.co/BAAI/bge - m3”来下载ChatGLM3 - 6B模型和bge - m3模型（也可以手动下载至本地然后使用scp命令上传至服务器中）。下载好后在当前目录下多出ChatGLM3 - 6B和bge - m3文件夹，如图15 - 55所示。然后，执行“conda create -n glm3 python=3.12”创建conda环境，再执行“conda activate glm3”激活环境。之后再执行“conda install pytorch torchvision torchaudio pytorch - cuda=12.1 -c pytorch -c nvidia”和“pip install -r requirements.txt”安装PyTorch和需要的Python包。最后，执行“export no_proxy="211.81.248.218"”（填写自己的服务器IP）和“nohup python api_server.py > glm3.log 2>&1 &”将程序挂在服务器后台运行即可，如图15 - 56所示，8001为部署的服务器端口。在浏览器中输入“211.81.248.218:8001/docs”可以查看FastAPI提供的接口文档，“211.81.248.218”是该服务器的IP，读者需要换成自己所使用服务器的IP。
```
(glm2) shuzhimin@218keg:~/CharacterAI/langchain_glm3$ ls
api_server.py bge - m3 chatglm3 - 6b README.md requirements.txt tools utils.py
(glm2) shuzhimin@218keg:~/CharacterAI/langchain_glm3$
```
### 图15 - 55 查看下载的chatglm3 - 6b和bge - m3

![image](https://github.com/user-attachments/assets/b89cac8d-3c75-47fe-8d04-92a94bb51ca6)

```
(glm3) shuzhimin@218keg:~/CharacterAI/langchain_glm3$ nohup python api_server.py > glm3.log 2>&1 &
[2] 217298
(glm3) shuzhimin@218keg:~/CharacterAI/langchain_glm3$ cat glm3.log
nohup: ignoring input
Setting eos_token is not supported, use the default one.
Setting pad_token is not supported, use the default one.
Setting unk_token is not supported, use the default one.
Loading checkpoint shards: 100%|███████████████████████████████████████| 7/7 [02:02:00, 2.37it/s]
INFO:     Started server process [217299]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
```

![image](https://github.com/user-attachments/assets/22f1e072-aac6-4f18-b849-4c50f82393f2)


### 图15 - 56 将api_server.py挂在服务器后台运行

#### 4. 后端部署

做好上述内容后，读者就可以开始部署后端。首先，保证在工程目录/CharacterAI下，根据example - conf.toml文件给出的模板，写一个自己的conf.toml文件。读者可以执行“cp example - conf.toml conf.toml”来复制一份example - conf.toml的内容，文件命名为conf.toml。注意，conf.toml内的配置一定要根据安装Qdrant、PostgreSQL和Minio以及部署微调后的模型和ChatGLM3 - 6B的实际情况来写，如果需要修改，可以执行“vim conf.toml”来修改里面的内容。如图15 - 57所示，需要修改服务器IP为自己实际部署它们的服务器IP、填写智谱的api_key等。

然后，设置执行“export PYTHONPATH=.”设置Python搜索包的路径为当前目录，执行“conda create -n character_ai python=3.12”来创建后端的Python环境，再执行“conda activate character_ai”进入创建好的环境中，再执行“pip install -r requirements.txt”安装好需要的库。之后执行“export no_proxy="211.81.248.218"”防止服务器代理对调用接口产生影响，其中211.81.248.218需要改成读者实际部署的服务器IP。最后，执行“nohup python app/main.py > log_file.log 2>&1 &”将后端挂在服务器后台运行。读者可以在浏览器中输入“211.81.248.218:8000/docs”查看FastAPI提供的接口文档，确认是否部署成功，能正常访问则部署成功。
```
(character_ai) shuzhimin@218keg:~/CharacterAI$ cp example - conf.toml conf.toml
(character_ai) shuzhimin@218keg:~/CharacterAI$ vim conf.toml
(character_ai) shuzhimin@218keg:~/CharacterAI$ cat conf.toml
[postgres]
host = '211.81.248.218'
port = 5432
username = 'ysukeg'
password = 'postgres'
database = 'characterai'

[zhipuai]
api_key = '********************************'

[fastapi]
host = '0.0.0.0'
port = 8000

[minio]
endpoint = '211.81.248.218:9000'
access_key = 'root'
secret_key = '12345678'
secure = false
bucket_name = 'test'

[admin]
username = 'admin'
password = 'admin'

[qdrant]
host = 'localhost'
collection_name ='my_collections'
prefer_gprc = false

[llm]
glm2_url = 'http://211.81.248.218:8086/character_llm'
glm3_url = 'http://211.81.248.218:8001/v1/chat/completions'
```
### 图15 - 57 example - conf.toml文件


![image](https://github.com/user-attachments/assets/4937f1a4-14cf-4d3e-b351-85ec598b747a)


#### 5. 前端部署

首先，进入源码文件中的front文件夹的路径下，该文件夹存放的是前端的代码，如图15 - 58所示。

然后，修改“/CharacterAI/front/src/plugins”路径下的global.js文件中的后端部署IP和端口，如图15 - 59部署后端的IP是211.81.248.218，端口是8000，需要将它换成部署后端的IP和端口。

其次，读者需要在“/CharacterAI/front”路径下创建Dockerfile文件、nginx.conf文件和.dockerignore文件。文件内容分别如图15 - 60～图15 - 62所示，这些文件已在该路径下给出。在Dockerfile文件中，设置代理让下载速度更快。在文件nginx.conf中，读者需要将server_name改成部署前端的服务器的IP。

```
(character_ai) shuzhimin@218keg:~/CharacterAI$ cd front/
(character_ai) shuzhimin@218keg:~/CharacterAI/front$ ll
total 288
drwxrwxr - x  7 shuzhimin shuzhimin  4096 Jul 21 18:47./
drwxrwxr - x  6 shuzhimin shuzhimin  4096 Jul 21 18:46../
drwxrwxr - x  2 shuzhimin shuzhimin  4096 Jul 21 18:47.idea/
-rw - rw - r--  1 shuzhimin shuzhimin  4996 Jul 21 18:46 LICENSE
-rw - rw - r--  1 shuzhimin shuzhimin   235 Jul 21 18:47 Dockerfile
-rw - rw - r--  1 shuzhimin shuzhimin   244 Jul 21 18:46.dockerignore
-rw - rw - r--  1 shuzhimin shuzhimin   160 Jul 21 18:40.env.development
-rw - rw - r--  1 shuzhimin shuzhimin   253 Jul 21 18:40.env.production
-rw - rw - r--  1 shuzhimin shuzhimin   256 Jul 21 18:40.env.staging
drwxrwxr - x  2 shuzhimin shuzhimin  4096 Jul 21 18:40 html/
-rw - rw - r--  1 shuzhimin shuzhimin   4096 Jul 21 18:40 index.html
-rw - rw - r--  1 shuzhimin shuzhimin   1071 Jul 21 18:40 LICENSE
-rw - rw - r--  1 shuzhimin shuzhimin   2216 Jul 21 18:47 nginx.conf
-rw - rw - r--  1 shuzhimin shuzhimin   1165 Jul 21 18:47 package.json
-rw - rw - r--  1 shuzhimin shuzhimin 203568 Jul 21 18:40 package - lock.json
drwxrwxr - x  3 shuzhimin shuzhimin  4096 Jul 21 18:40 public/
-rw - rw - r--  1 shuzhimin shuzhimin   8796 Jul 21 18:40 README.md
drwxrwxr - x 12 shuzhimin shuzhimin  4096 Jul 21 18:46 src/
-rw - rw - r--  1 shuzhimin shuzhimin   1919 Jul 21 18:40 vite.config.js
```


![image](https://github.com/user-attachments/assets/07194139-1538-48f1-8afb-f331c5ddb6fc)


### 图15 - 58 front内的文件
```
(character_ai) shuzhimin@218keg:~/CharacterAI/front/src/plugins$ cat global.js
const baseUrl = 'http://211.81.248.218:8000';
const domain = 'http://' + socket;
const menuList = [];
let lockPage = false;
let lockPagePassword = '';

export const minioConfig = {
  host: 'files.lulinyuan.com',
  port: 443,
  useSSL: true,
  accessKey: 'T3TCCDt6PC0vQmE8U',
  secretKey: '9g04xXwQDkaIXIv9VbVBoBpy2vZcY4mc',
  bucket: 'nongchang - app'
};

export default{
  menuList,  //菜单
  lockPage,
  domain,
  lockPagePassword,
  socket
}
```


### 图15 - 59 修改后端IP和端口

![image](https://github.com/user-attachments/assets/af711a52-66e2-4b0a-887b-cce0ba780b1f)

```
FROM node:18.16.0 as build - stage
WORKDIR /app
COPY package*.json./
RUN npm config set proxy http://proxy.example.com:port && \
    npm config set https - proxy https://proxy.example.com:port
RUN npm install
RUN npm cache clean --force
COPY.
RUN npm run build:prod

FROM nginx:stable - alpine as production - stage
RUN mkdir /app
COPY --from=build - stage /app/dist /app
COPY nginx.conf /etc/nginx/nginx.conf
```

![image](https://github.com/user-attachments/assets/7caafd01-dd65-4ece-ab31-d48508866b94)


### 图15 - 60 Dockerfile文件
```
user  nginx;
worker_processes  1;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet - stream;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    access_log  /var/log/nginx/access.log  main;
    sendfile        on;
    keepalive_timeout  65;

    server {
        listen       80;
        server_name  211.81.248.218;

        root   /app;
        index  index.html;
        try_files $uri $uri/ /index.html;

        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }
    }
}
```
### 图15 - 61 nginx.conf文件
```
**/node_modules
**/dist
```


![image](https://github.com/user-attachments/assets/8712a0ed-e13d-4c25-bf57-6d3b7dfecdae)


### 图15 - 62.dockerignore文件

最后，在“/CharacterAI/front”路径下分别执行“docker build. -t agent_ai”和“docker run -d -p 8900:80 agent_ai”，其中agent_ai为镜像的名字，可以自行更换，如图15 - 63所示。执行完成后，可以在浏览器上输入“211.81.248.218:8900”（211.81.248.218更换为读者部署前端的IP），看是否能进入系统页面。如果可以，那么已经成功部署该案例系统，如图15 - 64所示。
```
(character_ai) shuzhimin@218keg:~/CharacterAI/front$ docker build. -t agent_ai
[+] Building 59.6s (16/16) FINISHED
 => [internal] load build definition from Dockerfile                                 0.0s
 => => transferring dockerfile: 274B                                                 0.0s
 => [internal] load metadata for docker.io/library/nginx:latest                       0.0s
 => [internal] load metadata for docker.io/library/node:latest                        0.0s
 => [internal].dockerignore                                                         0.0s
 => => transferring context: 64B                                                      0.0s
 => [internal] load context                                                          2.90MB
 => => transferring context: 2.90MB                                                   0.0s
 => [production - stage 1/4] FROM docker.io/library/nginx:latest@sha256:a484B9eb60211f5299034ac88bc7d7f515b645828d03bc569f641918757e9b58a9e89f186604a99bd73b7 0.0s
 => [build - stage 1/6] FROM docker.io/library/node:latest@sha256:aba58f54e77a8a9f18ec36d25f9a4f1 0.0s
 => CACHED [build - stage 2/6] WORKDIR /app                                            0.0s
 => CACHED [build - stage 3/6] COPY package*.json./                                   0.0s
 => CACHED [build - stage 4/6] RUN npm install                                         0.0s
 => CACHED [build - stage 5/6] RUN npm cache clean --force                             0.0s
 => [build - stage 6/6] RUN npm run build:prod                                         59.5s
 => [production - stage 2/4] RUN mkdir /app                                            0.0s
 => [production - stage 3/4] COPY --from=build - stage /app/dist /app                   0.0s
 => [production - stage 4/4] COPY nginx.conf /etc/nginx/nginx.conf                     0.0s
 => exporting to image                                                               0.0s
 => => exporting layers                                                              0.0s
 => => writing image sha256:827944a6562f28be94696a7c783bbdee71289938f3988fc359338f61d1b4713ba 0.0s
 => => naming to docker.io/library/agent_ai                                          0.0s

(character_ai) shuzhimin@218keg:~/CharacterAI/front$ docker run -d -p 8900:80 agent_ai
8bc7d7f515b645828d03bc569f641918757e9b58a9
```


![image](https://github.com/user-attachments/assets/1322679d-1baf-4739-af9f-db327bbe2da4)


### 图15 - 63 使用docker部署前端

### 图15 - 64 进入系统登录页面


![image](https://github.com/user-attachments/assets/fa349630-4c16-4dfa-974f-ea6175806fd0)

### 15.8 本章小结
本章全面介绍了GAS的开发案例，详细阐述了从需求分析到系统设计、数据库构建、用户界面设计、后端接口实现、系统测试以及部署的完整流程。通过精心设计的用例分析、E - R图、算法流程图和系统架构，确保了系统的功能性、稳定性和用户友好性。同时，提供了详尽的测试用例和部署指南，为读者理解和实践智能体系统的开发提供了宝贵的指导。 
